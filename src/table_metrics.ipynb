{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11e6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from results import (\n",
    "    report_baseline,\n",
    "    report_letnet5,\n",
    "    report_resnet,\n",
    "    report_densenet,\n",
    "    report_mobilenet,\n",
    "    report_vit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom 6330\n",
    "# LeNet 61706\n",
    "# ResNet 11402\n",
    "# DenseNet 11666\n",
    "# MobileNet 14218\n",
    "# ViT 105546\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c24046a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LeNet5, ResNetMini, DenseNetTiny, MobileNetLite, ViTTiny, BaselineCNN\n",
    "\n",
    "lenet = LeNet5()\n",
    "resnet = ResNetMini(base_channels=4)\n",
    "densenet = DenseNetTiny()\n",
    "mobilenet = MobileNetLite()\n",
    "vit = ViTTiny()\n",
    "baseline = BaselineCNN()\n",
    "\n",
    "models = [\n",
    "    lenet,\n",
    "    resnet,\n",
    "    densenet,\n",
    "    mobilenet,\n",
    "    vit,\n",
    "    baseline,\n",
    "]\n",
    "\n",
    "import torch.nn as nn\n",
    "# for model in models:\n",
    "#     model:nn.Module\n",
    "#     parameters = [p.numel() for p in model.parameters()]\n",
    "#     param_sum = sum(parameters)\n",
    "#     # print(parameters)\n",
    "#     print(param_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be37e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004 13 baseline\n",
      "0.8907 16 letnet5\n",
      "0.911 29 resnet\n",
      "0.8971 18 densenet\n",
      "0.9155 41 mobilenet\n",
      "0.8809 25 vit\n"
     ]
    }
   ],
   "source": [
    "model_reports = {\n",
    "    'baseline': report_baseline,\n",
    "    'letnet5': report_letnet5,\n",
    "    'resnet': report_resnet,\n",
    "    'densenet': report_densenet,\n",
    "    'mobilenet': report_mobilenet,\n",
    "    'vit': report_vit,\n",
    "}\n",
    "\n",
    "for i, (name, report) in enumerate(model_reports.items()):\n",
    "    metric = report['test_accuracy']\n",
    "    epochs = np.arange(1, len(metric)+1)\n",
    "    \n",
    "    acc_argmax = np.argmax(metric)\n",
    "    print(np.round(metric[acc_argmax], decimals=4), epochs[acc_argmax], name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Train   Time (Mean ± Std)   Infer. Time (Mean ± Std) Epochs   Total Train Time   Train Time/Param.    Parameters} \\\\\n",
    "# LeNet-5 (lite)    & 20.29 ± 0.65  s & 1427 ± 77  ms & 21 & 426  s & 329 µs/K   & 62K \\\\\n",
    "# ResNet (lite)     & 81.93 ± 2.77  s & 3981 ± 205 ms & 34 & 2786 s & 7186 µs/K  & 11K \\\\\n",
    "# DenseNet (lite)   & 138.31 ± 3.33 s & 6958 ± 320 ms & 23 & 3181 s & 11856 µs/K & 12K \\\\\n",
    "# MobileNet (lite)  & 164.19 ± 2.78 s & 9590 ± 428 ms & 43 & 7060 s & 11548 µs/K & 14K \\\\\n",
    "# ViT (tiny)        & 136.28 ± 4.78 s & 7103 ± 439 ms & 27 & 3680 s & 1291 µs/K  & 106K \\\\\n",
    "# Custom CNN        & 25.8 ± 1.3    s & 1755 ± 66  ms & 18 & 464  s & 4076 µs/K  & 6K \\\\\n",
    "\n",
    "# Model} & Train Loss} & Test Loss} & Train Acc.} & Test Acc. (Epoch)} & Parameters} \\\\\n",
    "# LeNet-5 (lite)    & 0.1931 & 0.3203 & 92.74\\% & 89.07\\% (E=16) & 62K  \\\\\n",
    "# ResNet (lite)     & 0.2596 & 0.2488 & 90.62\\% & 91.10\\% (E=29) & 11K  \\\\\n",
    "# DenseNet (lite)   & 0.3372 & 0.3009 & 88.01\\% & 89.71\\% (E=18) & 12K  \\\\\n",
    "# MobileNet (lite)  & 0.2259 & 0.2464 & 91.91\\% & 91.55\\% (E=41) & 14K  \\\\\n",
    "# ViT (tiny)        & 0.2265 & 0.3306 & 91.41\\% & 88.09\\% (E=25) & 106K \\\\\n",
    "# Custom CNN        & 0.2616 & 0.2790 & 90.53\\% & 90.04\\% (E=13) & 6K   \\\\\n",
    "\n",
    "# Discussion topics from the results:\n",
    "# Lenet was considerably fast with respect to how many parameters the model uses.\n",
    "# Majority (95%) of the model parameters come from the linear layers in the classifier \n",
    "# which probably can be heavily be optimized meaning the model will be efficient computationally\n",
    "# despite the high potenial of state learning. This is also reflected through the loss and\n",
    "# accuracy measures showing the model achieved considerably better metrics on the training\n",
    "# dataset (best loss and acc out of all models) than the test dataset - this suggests the model\n",
    "# generalizes bad and may perhaps be under-complex in the form of feature learning capacity. \n",
    "# The LeNet model was true to the orignial design apart from the input size of the images \n",
    "# and it is an old design (1998) which may have made this a compute intensive design at the \n",
    "# time. Improvements for this model would probably consist of increased feature learning\n",
    "# capacity in the form of more convolutional layers or similar. \n",
    "\n",
    "# The ResNet model generalized well despite being the model with second to least trainable\n",
    "# parameters achieving a lower loss and higher accuracy for the test dataset than the training\n",
    "# dataset. The model achieved the second to best accuracy out of the models. ResNet also \n",
    "# held low training and inference times comparatively to DenseNet and MobileNet with similar\n",
    "# number of parameters. Downsampling help keeping the number of computations down. \n",
    "\n",
    "# DISCUSSION\n",
    "# Interesting article about how FashionMNIST accuracy increases with number of \n",
    "# trainable parameters (see graph). \n",
    "# \\href{https://www.mdpi.com/2227-7390/12/20/3174#:~:text=The%20developed%20CNN%2D3%2D128,Fashion%2DMNIST%20test%20image%20set.}{CNN 99.65\\% Accuracy}\n",
    "\n",
    "# How lightweight affects performance and how the lightweight models have \n",
    "# performed in realtion to what is expected from them in theory.\n",
    "\n",
    "# How ViT compared to the CNN architectures (not optimal for small datasets?)\n",
    "\n",
    "# Effects of parameters on time? Same effect on training time and inference time? \n",
    "\n",
    "# Early stopping effects\n",
    "# How increased patience could help, especially heavier models with more \n",
    "# parameters, to increase its learning streak as learning happens in a slower \n",
    "# pace and the risk of unlucky streaks of non decreasing loss could trigger \n",
    "# early stopping for low levels of patience when much learning potential is \n",
    "# still left (untapped). Interesting to see what loss each model reached, \n",
    "# which came the closes to zero and which stilly have much to give - potentially \n",
    "# better by higher patience and longer training rounds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6976b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548504197322789"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(400*120 + 120*84 + 84*10) / 61706"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
